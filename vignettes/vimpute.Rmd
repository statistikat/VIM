---
title: "Imputation Method vimpute"
author: "Eileen Vattheuer"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Imputation Method vimpute}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  fig.align = "center"
)
```

## Introduction

This vignette documents `vimpute()` according to the current implementation in `R/vimpute.R`.
`vimpute()` provides a flexible and robust way to impute missing values in tabular data. It performs iterative, sequential imputation, allowing later estimates to leverage earlier predictions. The function supports multiple learners—including tree-based, regularized, and robust regression methods—making it suitable for numeric, categorical, or mixed data with complex relationships.
Optional features include predictive mean matching (PMM) for numeric targets, formula-based modeling with transformations or interactions, factor level handling, per-variable tuning, and convergence monitoring. Outputs can include the imputed dataset, prediction histories, and tuning logs, depending on the chosen settings.

## Function Signature

```{r, eval=FALSE}
vimpute(
  data,
  considered_variables = names(data),
  method = setNames(as.list(rep("ranger", length(considered_variables))), considered_variables),
  pmm = FALSE,
  pmm_k = NULL,
  learner_params = NULL,
  formula = FALSE,
  sequential = TRUE,
  nseq = 10,
  eps = 0.005,
  imp_var = TRUE,
  pred_history = FALSE,
  tune = FALSE,
  verbose = FALSE
)
```

## Arguments

- `data`: input data (`data.table`) with missings.
- `considered_variables`: variables used in the imputation process.
- `method`: imputation learner.
  - single global method (for all variables with missings), e.g. `"ranger"`
  - named list per variable, e.g. `list(Sleep = "xgboost", Dream = "robust")`
  - supported: `"ranger"`, `"xgboost"`, `"regularized"`, `"robust"`
- `pmm`: Predictive Mean Matching setting.
  - single `TRUE/FALSE` globally
  - named list per variable
  - PMM is used only for numeric targets
- `pmm_k`: number of neighbors for PMM.
  - single integer globally
  - named list per variable
  - `NULL` (default): uses `k = 1` where PMM is enabled, otherwise `NULL`
- `learner_params`: optional hyperparameters.
  - per variable
  - per method (`ranger`, `xgboost`, `regularized`, `robust`)
  - global fallback
- `formula`: `FALSE` (default) or named list of formulas.
  - only supported with methods `"regularized"` and `"robust"`
  - response-side transforms supported in code: `log()`, `exp()`, `sqrt()`, `I(1/...)`
- `sequential`: if `TRUE`, runs iterative imputation across `nseq` iterations.
- `nseq`: max number of iterations (default `10`).
- `eps`: convergence threshold for early stopping (default `0.005`).
- `imp_var`: if `TRUE`, appends `<var>_imp` indicator columns.
- `pred_history`: if `TRUE`, returns prediction history.
- `tune`: `TRUE/FALSE` globally or named list per variable.
  - tuning is attempted around `round(nseq / 2)` for enabled variables
- `verbose`: prints debug/progress messages.

## Return Value

- Default return (`pred_history = FALSE` and `tune = FALSE`): imputed `data.table`.
- If `pred_history = TRUE` and/or any `tune` entry is `TRUE`: returns a list with:
  - `data`: imputed data
  - optional `pred_history`
  - optional `tuning_log`

## Data

To demonstrate the function, the `sleep` dataset from the `VIM` package is used. 

```{r, echo = FALSE, results='hide', message=FALSE, warning=FALSE}
library(VIM)
library(data.table)
```
```{r setup_2, message = FALSE}
data <- as.data.table(VIM::sleep)
a <- aggr(sleep, plot = FALSE)
plot(a, numbers = TRUE, prop = FALSE)
```

The left plot shows the amount of missings for each column in the dataset sleep and the right plot shows how often each combination of missings occur. For example, there are 9 rows which contain a missing in both NonD and Dream.

```{r, message = FALSE}
dataDS <- sleep[, c("Dream", "Sleep")]
marginplot(dataDS, main = "Missing Values")
```

The __<font color="red">red</font>__ boxplot on the left shows the distribution of all values of Sleep where Dream contains a missing value. 
The __<font color="#87ceeb">blue</font>__ boxplot on the left shows the distribution of the values of Sleep where Dream is observed.

## Basic Usage

### Default run

In the basic usage, the `vimpute()` function performs imputation using the default settings.

```{r, include=TRUE, results='hide', message=FALSE, warning=FALSE}
res <- vimpute(data = data)
```
```{r}
print(head(res, 3))
```

Results and information about missing/imputed values can be shown in the plot margins:

```{r}
dataDS <- as.data.frame(res[, c("Dream", "Sleep", "Dream_imp", "Sleep_imp")])
marginplot(dataDS, delimiter = "_imp", main = "Imputation with Default Model")
```

The default output is the imputed dataset and the prediction history.

In this plot three different colors are used in the top-right.
These colors represent the structure of missings.

* __<font color="#8b5a00">brown</font>__ points represent values where `Dream` was missing initially
* __<font color="#ffa500">beige</font>__ points represent values where `Sleep` was missing initially
* __black__ points represent values where both `Dream` and `Sleep` were missing
  initially
  
### Include prediction history 

This example demonstrates how to enable and inspect the prediction history, which records the model estimates for each iteration of the imputation process.

```{r, include=TRUE, results='hide', message=FALSE, warning=FALSE}
res_hist <- vimpute(
  data = data,
  pred_history = TRUE
)
```
```{r}
ph <- res_hist$pred_history
n  <- nrow(ph)

if (n >= 15) {
  first  <- ph[1:5, ]
  middle <- ph[(floor(n/2)-2):(floor(n/2)+2), ]
  last   <- ph[(n-4):n, ]
  print(first)
  cat("\n...\n...\n...\n\n")
  print(middle)
  cat("\n...\n...\n...\n\n")
  print(last)
  
} else {
  print(ph)
}
```
  
## Method Configuration

Specifies the machine learning method used for imputation of each variable:
- **`"robust"`**: Robust regression models  
  - `lmrob` for numeric variables: Implements MM-estimation for resistance to outliers
  - `glmrob` for factors: Uses robust estimators to reduce outlier influence 
- **`"regularized"`**: Regularized regression (`glmnet`)  
  - Uses elastic net regularization  
  - Automatically handles multicollinearity  
- **`"ranger"`**: Random Forest  
  - Fast implementation of random forests  
  - Handles non-linear relationships well  
- **`"xgboost"`**: Gradient Boosted Trees  
  - State-of-the-art tree boosting  
  - Handles mixed data types well  

### Global method  

Using a single global method applies the same imputation strategy to all variables with missing values. This is convenient when a consistent modeling approach is desired and simplifies configuration.

```{r, eval=FALSE}
res_xgb <- vimpute(
  data = data,
  method = "xgboost"
)
```

### Variable-specific methods

Variable-specific methods allow different imputation strategies for each variable, which can improve accuracy when variables have different distributions or relationships. This flexibility lets you combine robust, regularized, or tree-based models as appropriate.

```{r, eval=FALSE}
res_mixed <- vimpute(
  data = data,
  method = list(
    NonD = "robust",
    Dream = "ranger",
    Sleep = "xgboost",
    Span = "ranger",
    Gest = "regularized"
  )
)
```  

## PMM Configuration

Predictive Mean Matching (PMM) is an optional technique used to preserve the original data distribution when imputing numeric variables. Instead of directly predicting missing values, PMM selects observed values that are close to the predicted value, ensuring that imputed values remain realistic and consistent with the observed data.

### Global PMM with global `pmm_k`

Enabling PMM globally applies the same predictive mean matching approach to all numeric variables.
The `pmm_k` parameter controls the number of closest observed values considered for imputation.

```{r, eval=FALSE}
res_pmm <- vimpute(
  data = data,
  pmm = TRUE,
  pmm_k = 3
)
```

### Variable-specific PMM

For more fine-grained control, PMM can be enabled on a per-variable basis. This allows some variables to use standard model-based imputation while others benefit from PMM. Additionally, `pmm_k` can be specified individually for each variable, adjusting the number of nearest neighbors used for imputation depending on the variable’s characteristics or distribution.

```{r, eval=FALSE}
res_pmm_var <- vimpute(
  data = data,
  pmm = list(NonD = FALSE, Dream = TRUE, Sleep = TRUE, Span = FALSE),
  pmm_k = list(Dream = 1, Sleep = 5)
)
```

## Hyperparameter for chosen method

The `learner_params` argument allows passing hyperparameters to the underlying learner. Parameters can be defined globally, per variable, or per method.

### Global learner param

Global parameters are applied to all variables using the same method, unless more specific settings are provided.

```{r, eval=FALSE}
res_global_params <- vimpute(
  data = data,
  method = "xgboost",
  learner_params = list(
    nrounds = 200,
    max_depth = 4
  )
)
```

### Variable-specific learner param

Variable-specific parameters apply only to the specified target variable.

```{r, eval=FALSE}
res_var_params <- vimpute(
  data = data,
  method = "ranger",
  learner_params = list(
    Sleep = list(num.trees = 800)
  )
)
```

### Method-specific learner param

Method-specific parameters are shared across all variables using the same learner.

```{r, eval=FALSE}
res_method_params <- vimpute(
  data = data,
  method = list(
    Sleep = "ranger",
    Dream = "ranger",
    Span  = "xgboost"
  ),
  learner_params = list(
    ranger = list(num.trees = 600)
  )
)
```


## Formula Usage

Formulas are only supported for variables using `"regularized"` or `"robust"`.

```{r, eval=FALSE}
res_formula <- vimpute(
  data = data,
  method = list(
    NonD = "regularized",
    Span = "regularized",
    Gest = "robust"
  ),
  formula = list(
    NonD = NonD ~ Dream + Sleep,
    Span = Span ~ Dream:Sleep + Gest,
    Gest = log(Gest) ~ Sleep + exp(Span)
  )
)
```

## Tuning

`vimpute()` supports hyperparameter tuning to optimize model performance during imputation. By enabling `tune = TRUE`, the function will search for optimal settings for the chosen learners, which can improve prediction accuracy and the quality of imputed values.

### Global tuning

```{r, eval=FALSE}
res_tuned <- vimpute(
  data = data,
  sequential = TRUE,
  nseq = 10,
  tune = TRUE
)

names(res_tuned)
```

### Variable-specific tuning

```{r, eval=FALSE}
res_tuned_var <- vimpute(
  data = data,
  tune = list(Sleep = TRUE, Dream = FALSE)
)
```

## Iterative Settings

Imputation in `vimpute()` is iterative by default (`sequential = TRUE`), meaning missing values are updated across multiple passes to refine predictions. The number of iterations (`nseq`) and the convergence threshold (`eps`) can be adjusted

```{r, eval=FALSE}
res_iter <- vimpute(
  data = data,
  sequential = TRUE,
  nseq = 20,
  eps = 0.01
)
```

If `sequential = FALSE`, `nseq` is internally reduced to `1`.

## Restricting Variables

`vimpute()` allows you to restrict the imputation process to a subset of variables. This is useful when you want to focus only on certain key variables, reduce computation time, or avoid imputing variables that are complete or less relevant.

```{r, eval=FALSE}
res_subset <- vimpute(
  data = data,
  considered_variables = c("Sleep", "Dream", "Span", "BodyWgt"),
  method = "ranger"
)
```

Only `considered_variables` are used in the imputation workflow.



